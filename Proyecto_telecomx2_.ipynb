 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Executive Summary\n\n**Objective:** Build a churn classifier for the Telecom dataset.\n\n**Approach:** Load cleaned customer data, split once with stratification, and train two models (Logistic Regression baseline and Random Forest) using a single preprocessing pipeline (imputation + scaling/encoding).\n\n**Key metric:** ROC-AUC and recall for the churn class (positive = 1) are emphasized to capture likely churners while managing false alarms.\n"
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    classification_report,\n    roc_auc_score,\n    roc_curve,\n    confusion_matrix,\n    ConfusionMatrixDisplay,\n)\n\nRANDOM_STATE = 42\nplt.style.use(\"seaborn-v0_8\")\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Load data\nurl = \"https://raw.githubusercontent.com/sarahouses/proyecto_telecomx2/refs/heads/main/datos_tratados%20(1).csv\"\ndf = pd.read_csv(url, sep=\",\", encoding=\"utf-8\")\nprint(df.shape)\ndf.head()\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Basic cleaning\n# Drop identifier and ensure numeric columns are properly typed\nif \"customerID\" in df.columns:\n    df = df.drop(columns=[\"customerID\"])\n\n# Convert known numeric columns\nnum_candidates = [\"SeniorCitizen\", \"tenure\", \"Charges.Monthly\", \"Charges.Total\"]\nfor col in num_candidates:\n    if col in df.columns:\n        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n\n# Standardize target: churn yes -> 1, no -> 0\nif df[\"Churn\"].dtype == object:\n    df[\"Churn\"] = df[\"Churn\"].str.strip().str.lower().map({\"yes\": 1, \"no\": 0})\n\n# Final feature/target split\nX = df.drop(columns=[\"Churn\"])\ny = df[\"Churn\"].astype(int)\n\nprint(\"Target distribution:\n\", y.value_counts(normalize=True))\ndf.info()\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Minimal EDA: churn balance\nfig, ax = plt.subplots(figsize=(4,4))\ny.value_counts().plot(kind=\"bar\", ax=ax, color=[\"#4c72b0\", \"#dd8452\"])\nax.set_title(\"Churn class counts\")\nax.set_xlabel(\"Churn\")\nax.set_ylabel(\"Count\")\nplt.show()\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Train/test split (single split, stratified)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n)\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Column types\ncat_cols = X_train.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\nnum_cols = X_train.select_dtypes(include=[\"number\"]).columns.tolist()\n\nnumeric_pipeline = Pipeline(\n    steps=[\n        (\"imputer\", SimpleImputer(strategy=\"median\")),\n        (\"scaler\", StandardScaler()),\n    ]\n)\n\ncategorical_pipeline = Pipeline(\n    steps=[\n        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n    ]\n)\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_pipeline, num_cols),\n        (\"cat\", categorical_pipeline, cat_cols),\n    ]\n)\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def evaluate_model(clf, X_test, y_test, title=None, plot_roc=False):\n    y_pred = clf.predict(X_test)\n    if hasattr(clf, \"predict_proba\"):\n        y_scores = clf.predict_proba(X_test)[:, 1]\n    else:\n        y_scores = clf.decision_function(X_test)\n    roc_auc = roc_auc_score(y_test, y_scores)\n\n    print(\"Classification report (focus on recall/precision for churn = 1):\")\n    print(classification_report(y_test, y_pred, digits=3))\n    print(f\"ROC-AUC: {roc_auc:.3f}\")\n\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n    disp.plot(cmap=\"Blues\")\n    plt.title(title or \"Confusion Matrix\")\n    plt.show()\n\n    if plot_roc:\n        fpr, tpr, _ = roc_curve(y_test, y_scores)\n        plt.figure()\n        plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.3f})\")\n        plt.plot([0,1],[0,1], \"k--\", label=\"Chance\")\n        plt.xlabel(\"False Positive Rate\")\n        plt.ylabel(\"True Positive Rate\")\n        plt.title(title or \"ROC Curve\")\n        plt.legend()\n        plt.show()\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Logistic Regression (baseline)\nlog_reg = Pipeline(\n    steps=[\n        (\"preprocess\", preprocess),\n        (\"model\", LogisticRegression(max_iter=1000, class_weight=\"balanced\", n_jobs=-1, solver=\"liblinear\")),\n    ]\n)\n\nlog_reg.fit(X_train, y_train)\nevaluate_model(log_reg, X_test, y_test, title=\"Logistic Regression\", plot_roc=True)\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Random Forest (alternative)\nrf_clf = Pipeline(\n    steps=[\n        (\"preprocess\", preprocess),\n        (\"model\", RandomForestClassifier(\n            n_estimators=300,\n            max_depth=None,\n            class_weight=\"balanced\",\n            random_state=RANDOM_STATE,\n            n_jobs=-1,\n        )),\n    ]\n)\n\nrf_clf.fit(X_train, y_train)\nevaluate_model(rf_clf, X_test, y_test, title=\"Random Forest\", plot_roc=True)\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Model comparison helper (AUC focus)\nmodels = {\n    \"log_reg\": log_reg,\n    \"random_forest\": rf_clf,\n}\n\nresults = []\nfor name, model in models.items():\n    if hasattr(model, \"predict_proba\"):\n        scores = model.predict_proba(X_test)[:, 1]\n    else:\n        scores = model.decision_function(X_test)\n    results.append({\"model\": name, \"roc_auc\": roc_auc_score(y_test, scores)})\n\npd.DataFrame(results).sort_values(by=\"roc_auc\", ascending=False)\n",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2