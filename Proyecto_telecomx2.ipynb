 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telco Churn - Notebook mejorado\nNotebook reestructurado para limpiar el dataset, balancear la clase `Churn` y evaluar modelos con un flujo reproducible.\n"
   ]
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score, ConfusionMatrixDisplay\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de datos\nSe prioriza el CSV local y, si no existe, se usa la versión remota publicada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('datos_tratados (1).csv')\n",
    "REMOTE = 'https://raw.githubusercontent.com/sarahouses/proyecto_telecomx2/refs/heads/main/datos_tratados.csv'\n",
    "\n",
    "if DATA_PATH.exists():\n",
    "    df_raw = pd.read_csv(DATA_PATH)\n",
    "else:\n",
    "    df_raw = pd.read_csv(REMOTE)\n",
    "\n",
    "print(f'Shape: {df_raw.shape}')\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limpieza y estandarización\n- Se elimina el identificador `customerID`.\n- Se homogenizan valores tipo *No internet service*.\n- Se imputan faltantes numéricos con la mediana y se rellenan strings faltantes con `Missing`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "# Identificador\n",
    "df = df.drop(columns=['customerID'], errors='ignore')\n",
    "\n",
    "# Homogeneizar valores 'No internet service' -> 'No'\n",
    "cols_to_fix = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "for col in cols_to_fix:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].replace('No internet service', 'No')\n",
    "\n",
    "# Asegurar nombres coherentes\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "\n",
    "# Conversión numérica de cargos\n",
    "for col in ['Charges.Monthly', 'Charges.Total']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Target a 0/1\n",
    "target_col = 'Churn_Yes' if 'Churn_Yes' in df.columns else 'Churn'\n",
    "if target_col == 'Churn':\n",
    "    df[target_col] = df[target_col].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Reporte rápido de nulos\n",
    "nulls = df.isnull().sum().sort_values(ascending=False)\n",
    "print('Nulos > 0:\n",
    "', nulls[nulls > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Definición de variables y partición\nSe emplea una partición estratificada 80/20 para preservar la proporción de la clase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[target_col].astype(int)\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "cat_cols = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print('Distribución de entrenamiento:', y_train.value_counts(normalize=True).round(3))\n",
    "print('Distribución de prueba:', y_test.value_counts(normalize=True).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline de preprocesado y balanceo\nSe usa `ColumnTransformer` para tratar variables categóricas y numéricas y `SMOTE` para balancear la clase minoritaria dentro del conjunto de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = OneHotEncoder(handle_unknown='ignore', drop='first', sparse=False)\n",
    "numeric = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    ('cat', categorical, cat_cols),\n",
    "    ('num', numeric, num_cols)\n",
    "])\n",
    "\n",
    "def make_pipeline(model):\n",
    "    return Pipeline([\n",
    "        ('preprocess', preprocess),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('model', model)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entrenamiento y evaluación\nSe evalúan tres modelos complementarios: regresión logística, Random Forest y Gradient Boosting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=2000, n_jobs=-1),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=400, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "metrics = []\n",
    "reports = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = make_pipeline(model)\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    if hasattr(pipe.named_steps['model'], 'predict_proba'):\n",
    "        y_score = pipe.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_score = pipe.decision_function(X_test)\n",
    "\n",
    "    roc = roc_auc_score(y_test, y_score)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, digits=3)\n",
    "    reports[name] = report\n",
    "    metrics.append({\n",
    "        'Modelo': name,\n",
    "        'ROC_AUC': roc,\n",
    "        'Recall_1': report['1']['recall'],\n",
    "        'F1_1': report['1']['f1-score']\n",
    "    })\n",
    "\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "    print('ROC-AUC:', round(roc, 3))\n",
    "\n",
    "results = pd.DataFrame(metrics).sort_values(by='ROC_AUC', ascending=False)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Matriz de confusión del mejor modelo\nSe muestra la matriz de confusión para el modelo con mayor ROC-AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name = results.iloc[0]['Modelo']\n",
    "best_model = models[best_name]\n",
    "best_pipe = make_pipeline(best_model).fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_pipe.predict(X_test)\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax, cmap='Blues')\n",
    "ax.set_title(f'Matriz de confusión - {best_name}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Importancia de variables\nSe extraen las variables más influyentes para la regresión logística y el Random Forest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(ct):\n",
    "    names = []\n",
    "    for name, trans, cols in ct.transformers_:\n",
    "        if trans == 'drop':\n",
    "            continue\n",
    "        if hasattr(trans, 'get_feature_names_out'):\n",
    "            feats = trans.get_feature_names_out(cols)\n",
    "        else:\n",
    "            feats = cols\n",
    "        names.extend(feats)\n",
    "    return np.array(names)\n",
    "\n",
    "logit_pipe = make_pipeline(models['Logistic Regression']).fit(X_train, y_train)\n",
    "rf_pipe = make_pipeline(models['Random Forest']).fit(X_train, y_train)\n",
    "\n",
    "feat_names = get_feature_names(logit_pipe.named_steps['preprocess'])\n",
    "logit_coef = np.abs(logit_pipe.named_steps['model'].coef_).ravel()\n",
    "rf_imp = rf_pipe.named_steps['model'].feature_importances_\n",
    "\n",
    "imp_df = pd.DataFrame({\n",
    "    'Feature': feat_names,\n",
    "    'Logit_|coef|': logit_coef,\n",
    "    'RF_importance': rf_imp\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "for idx, col in enumerate(['Logit_|coef|', 'RF_importance']):\n",
    "    top = imp_df.sort_values(by=col, ascending=False).head(12).sort_values(by=col)\n",
    "    axes[idx].barh(top['Feature'], top[col])\n",
    "    axes[idx].set_title(col.replace('_', ' '))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusiones\n- El pipeline maneja limpieza, codificación y balanceo en un solo objeto reproducible.\n- Se reportan métricas comparables (ROC-AUC, Recall, F1) y se visualiza la matriz de confusión del mejor modelo.\n- Las gráficas de importancia facilitan la interpretación de los principales impulsores de churn.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
